{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cOMBkFKn6uEK"
   },
   "source": [
    "# Topic Modeling (Prepare)\n",
    "\n",
    "On Monday we talked about summarizing your documents using just token counts. Today, we're going to learn about a much more sophisticated approach - learning 'topics' from documents. Topics are a latent structure. They are not directly observable in the data, but we know they're there by reading them.\n",
    "\n",
    "> **latent**: existing but not yet developed or manifest; hidden or concealed.\n",
    "\n",
    "## Use Cases\n",
    "Primary use case: what the hell are your documents about? Who might want to know that in industry - \n",
    "* Identifying common themes in customer reviews\n",
    "* Discovering the needle in a haystack \n",
    "* Monitoring communications (Email - State Department) \n",
    "\n",
    "## Learning Objectives\n",
    "*At the end of the lesson you should be able to:*\n",
    "* Part 0: Warm-Up\n",
    "* Part 1: Describe how an LDA Model works\n",
    "* Part 2: Estimate a LDA Model with Gensim\n",
    "* Part 3: Interpret LDA results & Select the appropriate number of topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cxH0cRGX6uEL"
   },
   "source": [
    "# Part 0: Warm-Up\n",
    "How do we do a grid search? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rnyNg8sQ6uEL"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "boKWVkRz6uEO",
    "outputId": "2d3f688e-8cc8-44a4-9629-7c58285e1323"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Samples: 11314\n",
      "Testing Samples: 7532\n"
     ]
    }
   ],
   "source": [
    "# Load training data\n",
    "newsgroups_train = fetch_20newsgroups(subset='train', \n",
    "                                      remove=('headers', 'footers', 'quotes'))\n",
    "# Load testing data\n",
    "newsgroups_test = fetch_20newsgroups(subset='test', \n",
    "                                     remove=('headers', 'footers', 'quotes'))\n",
    "print(f'Training Samples: {len(newsgroups_train.data)}')\n",
    "print(f'Testing Samples: {len(newsgroups_test.data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create X and Y from data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w-39zg9a6uEQ"
   },
   "source": [
    "### GridSearch on Just Classifier\n",
    "* Fit the vectorizer and prepare BEFORE it goes into the gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "id": "2q3NmHEo6uEQ",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5128f39ff0d1ae1703c1aab52256a9cc",
     "grade": false,
     "grade_id": "cell-510807d1dad0e53b",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# create tfidf instant\n",
    "\n",
    "# transform data\n",
    "\n",
    "# create parameter dict\n",
    "\n",
    "# create model instance \n",
    "\n",
    "# instantiate a grid search object\n",
    "\n",
    "# optimize model parameters\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "gDkMaXvG83Zt",
    "outputId": "f3a55d86-209d-47b2-dd44-c23532ffcf2a"
   },
   "outputs": [],
   "source": [
    "# create and tranform a sample text \n",
    "\n",
    "# use the model to classify the sample tet \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WdVTuXKl6uEZ"
   },
   "source": [
    "### GridSearch with BOTH the Vectoizer & Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 668
    },
    "colab_type": "code",
    "deletable": false,
    "id": "97TjUtoI6uEZ",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "000124c970341034e97d5534ae87d4c1",
     "grade": false,
     "grade_id": "cell-9f20cda21fe03f05",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "outputId": "207e8cb3-5e82-4077-ac25-2406d21c3607"
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# create tfidf instance\n",
    "\n",
    "# create model instance \n",
    "\n",
    "# Create a pipline instance using tfidf and your model \n",
    "\n",
    "# create parameter dict\n",
    "\n",
    "# instantiate a grid search object\n",
    "\n",
    "# optimize model parameters\n",
    "\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IdIE67Us6uEc"
   },
   "outputs": [],
   "source": [
    "# pass a raw text sample into the optimized model in order to classify it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F2R2ACd36uEd"
   },
   "source": [
    "Advantages to using GS with the Pipe:\n",
    "* Allows us to make predictions on raw text increasing reproducibility. :)\n",
    "* Allows us to tune the parameters of the vectorizer along side the classifier. :D "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xbZjG6U86uEe"
   },
   "source": [
    "# Part 1: Describe how an LDA Model works"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Your Guide to Latent Dirichlet Allocation](https://medium.com/@lettier/how-does-lda-work-ill-explain-using-emoji-108abf40fa7d)\n",
    "\n",
    "[LDA Topic Modeling](https://lettier.com/projects/lda-topic-modeling/)\n",
    "\n",
    "[Topic Modeling with Gensim](https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "yPIlE_IeF0cX",
    "outputId": "11cab929-9e79-43fd-fee7-08f42113cf24"
   },
   "outputs": [],
   "source": [
    "# Download spacy model\n",
    "import spacy.cli\n",
    "spacy.cli.download(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qapChu_UGBFc"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "import spacy\n",
    "\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "colab_type": "code",
    "id": "qaMsy1XAGLxc",
    "outputId": "0a981642-93ef-4a95-c6a2-c5ca7c5151e0"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'content': data['data'],\n",
    "    'target': data['target'],\n",
    "    'target_names': [data['target_names'][i] for i in data['target']]\n",
    "})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "deletable": false,
    "id": "na2bkOcFGter",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5e6d91ee81e6014b8aef75dda13f927f",
     "grade": false,
     "grade_id": "cell-6ce62b4e40acee5f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "outputId": "6c8d1a19-3719-4e28-d8c6-d3202fdd6257"
   },
   "outputs": [],
   "source": [
    "# can visit (https://regex101.com/) for a regex python editor (has cheat sheets)\n",
    "\n",
    "# Remove whitespace\n",
    "\n",
    "# Remove Emails\n",
    "\n",
    "# Remove new line characters\n",
    "\n",
    "# Remove non-alphanumeric characters\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize(progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6EBPQXqEKE9P"
   },
   "outputs": [],
   "source": [
    "# create our tokens in the form of lemmas \n",
    "%%time\n",
    "df['lemmas'] = df['content'].parallel_apply(lambda x: [token.lemma_ for token in nlp(x) if (token.is_stop != True) and (token.is_punct != True)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The two main inputs to the LDA topic model are the dictionary (id2word) and the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "id": "1klqRpqtJxWc",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dd66ab4eff9f69a3e9be0aa57fdc2598",
     "grade": false,
     "grade_id": "cell-79d38b90e5c6e38b",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Create Dictionary\n",
    "\n",
    "# Term Document Frequency\n",
    "\n",
    "# stores (token id, token count) for each doc in the corpus\n",
    "\n",
    "# Human readable format of corpus (term-frequency)\n",
    "\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Estimate a LDA Model with Gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Train an LDA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fasvjf0VLQ2a"
   },
   "outputs": [],
   "source": [
    "### This cell runs the single-processor version of the model (slower)\n",
    "# %%time\n",
    "# lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "#                                            id2word=id2word,\n",
    "#                                            num_topics=20, \n",
    "#                                            chunksize=100,\n",
    "#                                            passes=10,\n",
    "#                                            per_word_topics=True)\n",
    "# lda_model.save('lda_model.model')\n",
    "# # https://radimrehurek.com/gensim/models/ldamodel.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### This cell runs the multi-processor version of the model (faster)\n",
    "%%time\n",
    "lda_multicore = gensim.models.ldamulticore.LdaMulticore(corpus=corpus,\n",
    "                                                        id2word=id2word,\n",
    "                                                        num_topics=20, \n",
    "                                                        chunksize=100,\n",
    "                                                        passes=10,\n",
    "                                                        per_word_topics=True,\n",
    "                                                        workers=12)\n",
    "\n",
    "\n",
    "lda_multicore.save('lda_multicore.model')\n",
    "# https://radimrehurek.com/gensim/models/ldamulticore.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import models\n",
    "#lda_multicore =  models.LdaModel.load('lda_multicore.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View the topics in LDA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JawR8yscLVNS"
   },
   "outputs": [],
   "source": [
    "# display the print_topics from the model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Interpret LDA results & Select the appropriate number of topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CYXi480VLaHK"
   },
   "outputs": [],
   "source": [
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim.prepare(lda_multicore, corpus, id2word)\n",
    "vis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is topic coherence?\n",
    "Topic Coherence measures score a single topic by measuring the degree of semantic similarity between high scoring words in the topic. These measurements help distinguish between topics that are semantically interpretable topics and topics that are artifacts of statistical inference.\n",
    "A set of statements or facts is said to be coherent, if they support each other. Thus, a coherent fact set can be interpreted in a context that covers all or most of the facts. An example of a coherent fact set is “the game is a team sport”, “the game is played with a ball”, “the game demands great physical efforts”\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rjtXk8J3LaXC"
   },
   "outputs": [],
   "source": [
    "def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=3):\n",
    "    \"\"\"\n",
    "    Compute c_v coherence for various number of topics\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    dictionary : Gensim dictionary\n",
    "    corpus : Gensim corpus\n",
    "    texts : List of input texts\n",
    "    limit : Max num of topics\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    model_list : List of LDA topic models\n",
    "    coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n",
    "    \"\"\"\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for num_topics in range(start, limit, step):\n",
    "        model = gensim.models.ldamulticore.LdaMulticore(corpus=corpus,\n",
    "                                                        id2word=id2word,\n",
    "                                                        num_topics=num_topics, \n",
    "                                                        chunksize=100,\n",
    "                                                        passes=10,\n",
    "                                                        per_word_topics=True,\n",
    "                                                        workers=10)\n",
    "        model_list.append(model)\n",
    "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "\n",
    "    return model_list, coherence_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model_list, coherence_values = compute_coherence_values(dictionary=id2word, corpus=corpus, texts=df['lemmas'], start=2, limit=22, step=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use these values for the plot if compute_coherence_values takes too long to run \n",
    "#coherence_values = [0.5054, 0.5332, 0.5452, 0.564, 0.5678, 0.5518, 0.519]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "limit=22; start=2; step=4;\n",
    "x = range(start, limit, step)\n",
    "plt.plot(x, coherence_values)\n",
    "plt.xlabel(\"Num Topics\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "plt.legend((\"coherence_values\"), loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the coherence scores\n",
    "for m, cv in zip(x, coherence_values):\n",
    "    print(\"Num Topics =\", m, \" has Coherence Value of\", round(cv, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the model and print the topics\n",
    "#optimal_model = model_list[1]\n",
    "optimal_model =  models.LdaModel.load('optimal_model.model')\n",
    "model_topics = optimal_model.show_topics(formatted=False)\n",
    "pprint(optimal_model.print_topics(num_words=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "REFERENCE_LS_DS_414_Topic_Modeling.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "U4-S1-NLP (Python3)",
   "language": "python",
   "name": "u4-s1-nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
